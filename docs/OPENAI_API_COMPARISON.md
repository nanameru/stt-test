# OpenAI 音声認識API比較

## 今回の要件

| 項目 | 要件 |
|-----|------|
| リアルタイム性 | 1〜2秒以内の遅延 |
| 言語 | 日本語（会議音声） |
| 話者分離 | 検証対象（Optional） |
| 用途 | 文字起こし（Transcription） |

---

## OpenAI 音声関連API一覧

| API | リアルタイム | 話者分離 | 用途 | 今回の要件 |
|-----|------------|---------|------|-----------|
| Whisper API (whisper-1) | ❌ バッチ処理 | ❌ | 文字起こし | △ |
| gpt-4o-transcribe | ❌ バッチ処理 | ❌ | 高精度文字起こし | △ |
| gpt-4o-mini-transcribe | ❌ バッチ処理 | ❌ | 軽量文字起こし | △ |
| **Realtime API (gpt-realtime)** | ✅ | ❌ | 音声対話 | ⭐ |

---

## 各API詳細

### 1. Whisper API (whisper-1)

**概要**: OpenAIの汎用音声認識モデル

| 項目 | 内容 |
|-----|------|
| モデル | whisper-1 |
| 処理方式 | バッチ処理（ファイルアップロード） |
| リアルタイム | ❌ 非対応 |
| 話者分離 | ❌ 非対応 |
| 日本語精度 | ○ 良好 |
| 料金 | $0.006 / 分 |

**評価**: ❌ リアルタイム要件を満たさない

---

### 2. gpt-4o-transcribe

**概要**: GPT-4oベースの高精度文字起こしモデル

| 項目 | 内容 |
|-----|------|
| モデル | gpt-4o-transcribe |
| 処理方式 | バッチ処理 |
| リアルタイム | ❌ 非対応 |
| 話者分離 | ❌ 非対応 |
| 日本語精度 | ◎ 非常に高い |
| 特徴 | Whisperより高精度、複雑な音声に強い |

**評価**: ❌ リアルタイム要件を満たさない（精度は最高クラス）

---

### 3. gpt-4o-mini-transcribe

**概要**: gpt-4o-transcribeの軽量版

| 項目 | 内容 |
|-----|------|
| モデル | gpt-4o-mini-transcribe |
| 処理方式 | バッチ処理 |
| リアルタイム | ❌ 非対応 |
| 話者分離 | ❌ 非対応 |
| 日本語精度 | ○ 良好 |
| 特徴 | 低コスト、高速処理 |

**評価**: ❌ リアルタイム要件を満たさない

---

### 4. Realtime API (gpt-realtime) ⭐ 最有力

**概要**: リアルタイム音声対話に特化したAPI

| 項目 | 内容 |
|-----|------|
| モデル | gpt-4o-realtime-preview / gpt-realtime |
| 処理方式 | **ストリーミング（WebRTC / WebSocket）** |
| リアルタイム | **✅ 対応（低遅延）** |
| 話者分離 | ❌ 非対応（外部ツール連携が必要） |
| 日本語精度 | ◎ 高い |
| 料金 | 入力: $32/100万トークン、出力: $64/100万トークン |

**主な特徴**:
- 音声入力→テキスト→音声出力を**統合処理**（従来の3段階処理より低遅延）
- WebRTC / WebSocket によるリアルタイムストリーミング
- 画像入力にも対応
- SIP（電話網）連携可能
- 感情やニュアンスの認識が向上

**接続方式**:
| 方式 | 用途 |
|-----|------|
| WebRTC | クライアントアプリ（Web/モバイル）向け |
| WebSocket | サーバー間通信向け |

**評価**: ⭐ **リアルタイム要件を満たす唯一のOpenAI API**

---

## 今回の要件との適合性

| 要件 | Whisper | gpt-4o-transcribe | Realtime API |
|-----|---------|-------------------|--------------|
| リアルタイム（1-2秒） | ❌ | ❌ | ✅ |
| 日本語精度 | ○ | ◎ | ◎ |
| 話者分離 | ❌ | ❌ | ❌ |
| 文字起こし専用 | ✅ | ✅ | △（対話向け） |

---

## 推奨構成

### OpenAI APIでリアルタイムSTTを実現する場合

```
┌─────────────────────────────────────────────────────────┐
│  Realtime API (gpt-realtime)                           │
│  ├─ 接続: WebSocket / WebRTC                           │
│  ├─ リアルタイム性: ✅ 低遅延                          │
│  └─ 日本語精度: ◎                                     │
├─────────────────────────────────────────────────────────┤
│  話者分離: pyannote.audio（別途連携）                  │
│  └─ Realtime APIには話者分離機能がないため            │
└─────────────────────────────────────────────────────────┘
```

---

## 注意点

### Realtime APIの制限事項

1. **音声対話向け設計**: 
   - 本来は音声対話（STT→処理→TTS）向け
   - 文字起こし専用として使う場合は出力側の設定調整が必要

2. **話者分離非対応**:
   - 複数話者の識別には外部ツール（pyannote等）との連携が必要

3. **コスト**:
   - Whisper APIより高コスト
   - 長時間の会議録音には向かない可能性

### バッチ処理API（Whisper/gpt-4o-transcribe）の活用シーン

- 録音済み音声ファイルの文字起こし
- リアルタイム性が不要な後処理
- **gpt-4o-transcribe**: 最高精度が必要な場合

---

## 料金比較

| API | 料金 | 備考 |
|-----|------|------|
| Whisper API | $0.006/分 | 最安 |
| gpt-4o-transcribe | 要確認 | 高精度 |
| Realtime API（入力） | $32/100万トークン | リアルタイム |
| Realtime API（出力） | $64/100万トークン | リアルタイム |

---

## 結論

### OpenAI APIで今回の要件を満たすには

| 要件 | 対応API | 対応状況 |
|-----|---------|---------|
| リアルタイム | Realtime API | ✅ |
| 日本語精度 | Realtime API | ✅ |
| 話者分離 | **外部ツール必須** | ⚠️ |

**Realtime API (gpt-realtime)** が唯一のリアルタイム対応APIですが、話者分離には対応していないため、**pyannote.audio**との連携が必要です。

### 比較: OpenAI vs ローカルモデル

| 項目 | Realtime API | kotoba-whisper + pyannote |
|-----|--------------|---------------------------|
| リアルタイム | ✅ | ✅ |
| 日本語精度 | ◎ | ◎（日本語特化） |
| 話者分離 | ❌（外部連携要） | ✅（pyannote統合） |
| コスト | 従量課金（高め） | 無料（計算リソースのみ） |
| 導入容易性 | ○（API呼び出し） | △（環境構築必要） |

---

## 参考リンク

- [OpenAI Realtime API ドキュメント](https://platform.openai.com/docs/guides/realtime)
- [Azure OpenAI Realtime Audio クイックスタート](https://learn.microsoft.com/ja-jp/azure/ai-services/openai/realtime-audio-quickstart)
- [gpt-realtime 紹介記事](https://openai.com/ja-JP/index/introducing-gpt-realtime/)
- [OpenAI Audio API](https://platform.openai.com/docs/guides/speech-to-text)

