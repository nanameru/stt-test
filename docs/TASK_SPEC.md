# リアルタイムSTT精度検証タスク

## 目的

デスクトップアプリ型での実装に向けた、**最適な音声認識APIおよびモデルを選定**するため。

## 要件

- **リアルタイム** or **1〜2秒遅延**でできるAPI/処理機構

## 検証対象候補

| # | API/モデル | 備考 |
|---|-----------|------|
| 1 | GPT Transcribe (Whisper API) | OpenAI公式 |
| 2 | GPT-5.? STT | 要確認 |
| 3 | Gemini 2.5 Pro STT | 1〜2秒以内でできるなら |
| 4 | Gemini Live API の STT | Google Live API |
| 5 | セルフホスト系 (pyannote等) | ローカル実行 |
| 6 | Groq経由 Whisper (whisper-large-v3) | ほぼノータイム実績あり |

> ※ 最大4〜5個に絞り込み予定

## タスク手順

### 1. 検証するAPIの確定
- **期限**: 本日中に吉田さんと合意
- **内容**: 候補をリストアップし、最大4〜5個に絞る

### 2. リアルタイム文字起こしの実行検証
- **期限**: 月曜日
- **内容**: 合意した各APIを使用して文字起こしテスト
- **使用データ**: サンプル会議データ
- **実施方法**: 
  - PCでAPIを待ち受け状態にする
  - スマホのスピーカー等から会議データを再生
  - **リアルタイムに音声を拾わせる形式**で実行（ファイルアップロードではない）

### 3. 話者分離（Diarization）の検証
- **期限**: 火曜日（Optional）
- **内容**: リアルタイム処理の中で「話者が複数いること（Speaker A, Speaker B...）」が正しく認識・分離されているか確認
- **補足**: タスク2と一緒にしても時間が変わらないなら同時実施OK

### 4. 話者割り当ての検証
- **期限**: Optional
- **内容**: 会議参加者リスト（例: 女性1人 + 男性2人）を用意し、会議内容からGemini等に話者を推定させて検証

## アウトプットイメージ

各APIについて以下の項目をまとめた表/ドキュメント:

| 評価項目 | 説明 |
|---------|------|
| 文字起こし精度 | 体感でOK、ラグの有無など |
| 文字起こしのリアルタイム性 | 遅延時間 |
| 話者分離の可否 | ○/△/× |
| 話者割り当ての可否 | ○/△/× |
| コスト感 | ざっくりのAPI単価 |

## 検証結果テンプレート

| API | 精度 | リアルタイム性 | 話者分離 | 話者割り当て | コスト |
|-----|------|---------------|---------|-------------|--------|
| GPT Transcribe (Whisper) | - | - | - | - | - |
| Gemini 2.5 Pro STT | - | - | - | - | - |
| Gemini Live API | - | - | - | - | - |
| Groq Whisper | - | - | - | - | - |
| (その他) | - | - | - | - | - |

## 参考リンク

- [Groq Whisper Playground](https://console.groq.com/playground?model=whisper-large-v3)

## 備考

- 正誤判定はGemini 3思考モードで教師データを作成し、自動判定させる方式を推奨
- 前処理系は今回の要件からは一旦保留
- 不明点があればハドルで相談可能

