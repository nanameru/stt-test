# リアルタイムSTT精度検証タスク

## 目的

**Webアプリ型**での実装に向けた、**最適な音声認識APIおよびモデルを選定**するため。

## 要件

- **リアルタイム** or **1〜2秒遅延**でできるAPI/処理機構
- **Webブラウザ上で動作**するアプリケーション（Next.js）
- ブラウザのマイクAPI（getUserMedia）を使用したリアルタイム音声入力

## 検証対象候補

| # | API/モデル | 備考 |
|---|-----------|------|
| 1 | GPT Transcribe (Whisper API) | OpenAI公式 |
| 2 | Gemini 2.5 Pro STT | 1〜2秒以内でできるなら |
| 3 | Gemini Live API の STT | Google Live API |
| 4 | Groq経由 Whisper (whisper-large-v3) | ほぼノータイム実績あり |

> ※ 4つのAPIを検証対象とする

## 実装機能

### コア機能
1. **リアルタイム音声入力** - ブラウザのgetUserMediaでマイクから音声をキャプチャ
2. **STT API統合** - 各APIへの音声ストリーミング送信
3. **文字起こし結果のリアルタイム表示** - 各APIの結果を並列表示
4. **遅延時間の測定** - 発話から文字起こし表示までの時間を計測

### オプション機能
5. **話者分離（Diarization）表示** - Speaker A, B等のラベル付き表示
6. **話者割り当て** - Geminiを使用した話者推定
7. **評価結果の記録・比較** - 各APIの評価表を自動生成

## タスク手順

### 1. 検証するAPIの確定
- **内容**: 上記4つのAPIを検証対象とする

### 2. リアルタイム文字起こしの実行検証
- **内容**: 各APIを使用して文字起こしテスト
- **使用データ**: サンプル会議データ
- **実施方法**: 
  - Webアプリでマイクを有効化
  - スマホのスピーカー等から会議データを再生
  - **リアルタイムに音声を拾わせる形式**で実行（ファイルアップロードではない）

### 3. 話者分離（Diarization）の検証（Optional）
- **内容**: リアルタイム処理の中で「話者が複数いること（Speaker A, Speaker B...）」が正しく認識・分離されているか確認
- **補足**: タスク2と一緒にしても時間が変わらないなら同時実施OK

### 4. 話者割り当ての検証（Optional）
- **内容**: 会議参加者リスト（例: 女性1人 + 男性2人）を用意し、会議内容からGemini等に話者を推定させて検証

## アウトプットイメージ

各APIについて以下の項目をまとめた表/ドキュメント:

| 評価項目 | 説明 |
|---------|------|
| 文字起こし精度 | 体感でOK、ラグの有無など |
| 文字起こしのリアルタイム性 | 遅延時間 |
| 話者分離の可否 | ○/△/× |
| 話者割り当ての可否 | ○/△/× |
| コスト感 | ざっくりのAPI単価 |

## 検証結果テンプレート

| API | 精度 | リアルタイム性 | 話者分離 | 話者割り当て | コスト |
|-----|------|---------------|---------|-------------|--------|
| GPT Transcribe (Whisper) | - | - | - | - | - |
| Gemini 2.5 Pro STT | - | - | - | - | - |
| Gemini Live API | - | - | - | - | - |
| Groq Whisper | - | - | - | - | - |
| (その他) | - | - | - | - | - |

## 参考リンク

- [Groq Whisper Playground](https://console.groq.com/playground?model=whisper-large-v3)

## 備考

- 正誤判定はGemini 3思考モードで教師データを作成し、自動判定させる方式を推奨
- 前処理系は今回の要件からは一旦保留
- 不明点があればハドルで相談可能

